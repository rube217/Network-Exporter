{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, sqlalchemy as sql, cx_Oracle as ora,  sqlite3, datetime as dt, re \n",
    "ora.init_oracle_client(lib_dir=r\"C:/Oracle_64/product/11.2.0/client_1/BIN/\")\n",
    "\n",
    "engine_adms = sql.create_engine(\"mssql+pyodbc://EpsaReportes:cmXoasys2@10.238.109.61\\OASYSHDB:20010/ADMS_QueryEngine?driver=SQL Server\")\n",
    "engine_oracle = sql.create_engine(\"oracle+cx_oracle://RDJARAMILLO:Berlin22+@PV10262/arcgis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_info = pd.read_sql_query(\"\"\"SELECT ID\n",
    "      ,EXTRACT_ALIAS\n",
    "      ,EXTRACT_STATE_ID\n",
    "      ,EXTRACT_SOURCE_ID\n",
    "      ,DESCRIPTION\n",
    "      ,CREATED_DATE\n",
    "      ,LAST_MODIFIED_DATE\n",
    "      ,FILENAME\n",
    "      ,COMMENT\n",
    "  FROM CSRepo.dbo.EXTRACT_INFO\"\"\", engine_adms, coerce_float=False)\n",
    "\n",
    "extract_state = pd.read_sql_query(\"\"\"SELECT ID\n",
    "      ,STATE_NAME\n",
    "  FROM CSRepo.dbo.EXTRACT_STATE\"\"\", engine_adms, coerce_float=False)\n",
    "\n",
    "extract_source = pd.read_sql_query(\"\"\"SELECT ID\n",
    "      ,SOURCE_NAME\n",
    "  FROM CSRepo.dbo.EXTRACT_SOURCE\"\"\", engine_adms, coerce_float=False)\n",
    "\n",
    "extract_hist = pd.read_sql_query(\"\"\"SELECT EXTRACT_ID\n",
    "      , USERNAME\n",
    "      , TRANSITION_TIME\n",
    "  FROM CSRepo.dbo.EXTRACT_HISTORY\"\"\", engine_adms, coerce_float=False)\n",
    "\n",
    "changeset_extract_dependency = pd.read_sql_query(\"\"\"SELECT CHANGESET_ID\n",
    "      ,EXTRACT_ID\n",
    "  FROM CSRepo.dbo.CHANGESET_EXTRACT_DEPENDENCY\"\"\", engine_adms, coerce_float=False)\n",
    "\n",
    "changeset_info = pd.read_sql_query(\"\"\"SELECT CHANGESET_STATE_ID\n",
    "      , CHANGESET_TYPE_ID\n",
    "      , DESCRIPTION\n",
    "      , ID\n",
    "      , LAST_MODIFIED_DATE\n",
    "  FROM CSRepo.dbo.CHANGESET_INFO\"\"\", engine_adms, coerce_float=False)\n",
    "\n",
    "changeset_state = pd.read_sql_query(\"\"\"SELECT STATE_NAME\n",
    "      , ID FROM CSRepo.dbo.CHANGESET_STATE\"\"\",engine_adms, coerce_float=False)\n",
    "\n",
    "changeset_hist = pd.read_sql_query(\"\"\"SELECT CHANGESET_ID\n",
    "      , OLD_CHANGESET_STATE_ID\n",
    "      , NEW_CHANGESET_STATE_ID\n",
    "      , USERNAME\n",
    "      , TRANSITION_TIME\n",
    "  FROM CSRepo.dbo.CHANGESET_HISTORY\"\"\", engine_adms, coerce_float=False)\n",
    "\n",
    "changeset_type = pd.read_sql_query(\"SELECT ID, TYPE_NAME  FROM CSRepo.dbo.CHANGESET_TYPE\",engine_adms, coerce_float=False)\n",
    "\n",
    "gis_jobs = pd.read_sql_query(\"\"\"SELECT JJSX.job_id, jj.JOB_NAME, jjs.STEP_NAME as current_status, v.owner || '.' || v.name as version_name, jj.NOTES , jj.DESCRIPTION , jj.OWNED_BY \n",
    "    FROM GRED_ADMINIS.JTX_STEP_STATUS jjsx \n",
    "    LEFT JOIN GRED_ADMINIS.JTX_JOB_STEP jjs ON jjs.STEP_ID  = JJSX.step_id\n",
    "    LEFT JOIN GRED_ADMINIS.JTX_JOBS jj ON jj.JOB_ID = jjsx.JOB_ID \n",
    "    LEFT JOIN sde.versions v ON v.name LIKE '%'|| jj.JOB_NAME ||'%'\n",
    "    WHERE 1 = 1\n",
    "    AND jjs.STEP_NAME IN ('Espera ConfirmaciÃ³n ADMS','Confirmar al ADMS','Promover en ADMS', ' Rechazar en ADMS','Finalizado')\n",
    "    AND jjsx.STATUS = 'S'\n",
    "    \"\"\", engine_oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_Invoker1_file = pd.read_csv(r'\\\\10.240.160.176\\f$\\Network Exporter Invoker\\Log\\NetworkExporterExecutionService.log', sep='\\r',header = None)\n",
    "NE_Invoker1_file['Machine'] = 'PV10219'\n",
    "NE_Invoker2_file = pd.read_csv(r'\\\\10.240.160.161\\e$\\Network Exporter Invoker\\Log\\NetworkExporterExecutionService.log', sep='\\r',header = None)\n",
    "NE_Invoker2_file['Machine'] = 'PV10270'\n",
    "NE_Invoker = pd.concat([NE_Invoker1_file,NE_Invoker2_file ])\n",
    "NE_Invoker_Pending =  NE_Invoker[NE_Invoker[0].str.contains('ColaMensajes.Encolar')].reset_index(drop=True)\n",
    "NE_Invoker_Executed =  NE_Invoker[NE_Invoker[0].str.contains('Se esta realizando la siguiente llamada')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_Invoker_Pending['Datetime'] = NE_Invoker_Pending[0].str.split('.',expand=True)[0]\n",
    "NE_Invoker_Pending[['Version','KindExecution','FeederList']] = NE_Invoker_Pending[0].str.split('Version:|kindExportation:|listFeeders:',expand=True)[[1,2,3]]\n",
    "NE_Invoker_Pending.KindExecution = NE_Invoker_Pending.KindExecution.str.split(',',expand = True)[0]\n",
    "NE_Invoker_Pending.Version = NE_Invoker_Pending.Version.str[:-2]\n",
    "NE_Invoker_Pending.Datetime = NE_Invoker_Pending.Datetime.replace({'a':'AM','p':'PM'},regex=True)\n",
    "NE_Invoker_Pending.Datetime = list(map(lambda x: dt.datetime.strptime(x,'%d/%m/%Y %I:%M:%S %p'), NE_Invoker_Pending.Datetime))\n",
    "NE_Invoker_Pending = NE_Invoker_Pending.drop(columns = 0).sort_values(by='Datetime').reset_index(drop=True)\n",
    "NE_Invoker_Pending['id'] =  NE_Invoker_Pending.apply(lambda x: re.search('20\\d+',x.Version.split('.')[-1]).group(0) + format(sum((ord(x)) for x in x.Version.split('.')[0]),'04d') if ('GIS' in x.Version and x.KindExecution == 'P') else format((int(x.Datetime.timestamp())*10000 + x.name),'015d'),axis=1)\n",
    "NE_Invoker_Pending['GisJobid'] =  NE_Invoker_Pending['Version'].apply(lambda x: re.search('20\\d+',x.split('.')[-1]).group(0) if 'GIS' in x else format(0,'011d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_Invoker_Executed['Datetime'] = NE_Invoker_Executed[0].str.split('.',expand=True)[0]\n",
    "NE_Invoker_Executed[['Version','KindExecution','FeederList']] = NE_Invoker_Executed[0].str.split('\"',expand=True)[[3,7,5]]\n",
    "NE_Invoker_Executed.Datetime = NE_Invoker_Executed.Datetime.replace({'a':'AM','p':'PM'},regex=True)\n",
    "NE_Invoker_Executed.Datetime = list(map(lambda x: dt.datetime.strptime(x,'%d/%m/%Y %I:%M:%S %p'), NE_Invoker_Executed.Datetime))\n",
    "NE_Invoker_Executed = NE_Invoker_Executed.drop(columns=0).sort_values(by='Datetime').reset_index(drop=True)\n",
    "NE_Invoker_Executed['id'] = ''#list(map(lambda x: '{Datetime}_{sum}'.format(Datetime= x.strftime('%Y%m%d%H%M%S'),sum = int(x.year)+int(x.month)*4+int(x.day)+int(x.hour)*70+int(x.minute)*10+int(x.second)),NE_Invoker_Executed.Datetime))\n",
    "\n",
    "for i in NE_Invoker_Pending.index:\n",
    "    subset = NE_Invoker_Executed.loc[\n",
    "                (NE_Invoker_Executed.FeederList == NE_Invoker_Pending.loc[i,'FeederList']) & \n",
    "                (NE_Invoker_Executed.Version== NE_Invoker_Pending.loc[i,'Version']) & \n",
    "                (NE_Invoker_Executed.Machine== NE_Invoker_Pending.loc[i,'Machine']) &\n",
    "                (NE_Invoker_Executed.Datetime >= NE_Invoker_Pending.loc[i,'Datetime']) &\n",
    "                (NE_Invoker_Executed.id == ''),:]\n",
    "    \n",
    "    NE_Invoker_Executed.loc[subset.index.min(),'id'] = NE_Invoker_Pending.loc[i,'id']\n",
    "\n",
    "NE_Invoker_Executions = NE_Invoker_Pending.merge(NE_Invoker_Executed[['id','Datetime']], on = 'id', how='left').rename(columns={'Datetime_x':'RecievedDatetime','Datetime_y':'ExecutionDatetime'})\n",
    "NE_Invoker_Executions['Executed'] = NE_Invoker_Executions['ExecutionDatetime'].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_info['STATE_NAME'] = extract_info.merge(extract_state,left_on='EXTRACT_STATE_ID', right_on='ID', how = 'left')['STATE_NAME']\n",
    "extract_info['SOURCE_NAME'] = extract_info.merge(extract_source,left_on='EXTRACT_SOURCE_ID', right_on='ID', how = 'left')['SOURCE_NAME']\n",
    "changeset_info['STATE_NAME'] = changeset_info.merge(changeset_state,left_on='CHANGESET_STATE_ID', right_on='ID', how = 'left')['STATE_NAME']\n",
    "changeset_info['SOURCE_NAME'] = changeset_info.merge(changeset_type,left_on='CHANGESET_TYPE_ID', right_on='ID', how = 'left')['TYPE_NAME']\n",
    "changeset_hist['OLD_CHANGESET_STATE'] = changeset_hist.merge(changeset_state, left_on='OLD_CHANGESET_STATE_ID', right_on='ID', how='left')['STATE_NAME']\n",
    "changeset_hist['NEW_CHANGESET_STATE'] = changeset_hist.merge(changeset_state, left_on='NEW_CHANGESET_STATE_ID', right_on='ID', how='left')['STATE_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changeset_info.merge(changeset_state,left_on='CHANGESET_STATE_ID', right_on='ID')['STATE_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect(r'\\\\10.240.160.176\\g$\\Data\\MMRepo.db3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_Invoker_Pending[['Id','Version','GisJobId']].rename(columns={'Id':'id','Version':'version_name','GisJobId':'gis_job_id','FeederList':'feeder_list'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = NE_Invoker_Pending[['id','GisJobid']].rename(columns={'Version':'version_name','GisJobid':'gis_job_id','FeederList':'feeder_list'}).drop_duplicates()\n",
    "\n",
    "\n",
    "Test.to_sql('Network_Exporter_Jobs',con=connection, index = False, index_label='id', if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis_jobs = gis_jobs.loc[gis_jobs.job_name.drop_duplicates().index,:].reset_index(drop=True)\n",
    "gis_jobs.to_sql('GIS_Jobs',con=connection,if_exists='append',index=False, index_label='job_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_Invoker_Pending.to_sql('NE_Pending_Jobs',con=connection, if_exists='replace', index_label=)\n",
    "NE_Invoker_Executed.to_sql('NE_Executed_Jobs',con=connection, if_exists='replace')\n",
    "extract_info.to_sql('Extracts',con=connection,if_exists='replace')\n",
    "changeset_info.to_sql('Changesets',con=connection,if_exists='replace')\n",
    "#gis_jobs.to_sql('GIS_Jobs',con=connection,if_exists='replace')\n",
    "changeset_extract_dependency.to_sql('Changeset_Extract_Dependency',con=connection,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "n = 0\n",
    "for root,dir,files in os.walk('//10.240.160.176/f$/Network Exporter/Archive'):\n",
    "    for file in files:\n",
    "        if file == 'ABORT.log':\n",
    "            n +=1\n",
    "            print(root+'/'+file)\n",
    "    #print(files)\n",
    "    # for file in files:\n",
    "    #     if FeederCID in file:\n",
    "    #         FileChoosen[1] = max(FileChoosen[1], os.path.getctime(root+'/'+file))\n",
    "    #         FileChoosen[0] = root+'/'+file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in NE_Invoker_Pending.index:\n",
    "    subset = NE_Invoker_Executed.loc[\n",
    "                (NE_Invoker_Executed.FeederList == NE_Invoker_Pending.loc[i,'FeederList']) & \n",
    "                (NE_Invoker_Executed.Version== NE_Invoker_Pending.loc[i,'Version']) & \n",
    "                (NE_Invoker_Executed.Machine== NE_Invoker_Pending.loc[i,'Machine']) &\n",
    "                (NE_Invoker_Executed.datetime >= NE_Invoker_Pending.loc[i,'datetime']) &\n",
    "                (NE_Invoker_Executed.CustomId == ''),:]\n",
    "    \n",
    "    NE_Invoker_Executed.loc[subset.index.min(),'CustomId'] = NE_Invoker_Pending.loc[i,'CustomId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_Invoker_Executions = NE_Invoker_Pending.merge(NE_Invoker_Executed[['CustomId','datetime']], on = 'CustomId', how='left').rename(columns={'datetime_x':'RecievedDatetime','datetime_y':'ExecutionDatetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime as dt, pandas as pd\n",
    "\n",
    "def get_aborts_messages(exporters_roots):\n",
    "    try:\n",
    "        Abort_dataframe = pd.DataFrame([],columns={'Job','Timestamp','AbortReason'})\n",
    "        for root in exporters_roots:\n",
    "            print('procesando',root)\n",
    "            for i in os.listdir(root):\n",
    "\n",
    "                abort_path_patch = root+i+'/Output.Patch/Log/ABORT.log'\n",
    "                abort_path = root+i+'/Output/Log/ABORT.log'\n",
    "\n",
    "                if os.path.exists(abort_path_patch):\n",
    "\n",
    "                    abort_file = open(abort_path_patch)\n",
    "                    time_stamp = dt.datetime.fromtimestamp(os.path.getctime(abort_path_patch))#os.path.getctime(abort_path_patch))\n",
    "                    Abort_dataframe = Abort_dataframe.append({'Job':i,'Timestamp':time_stamp,'AbortReason':abort_file.read()},ignore_index=True)\n",
    "                    # if(abort_file.read().__contains__('Respuesta del servicio')):\n",
    "                        \n",
    "                    #     time_stamp = dt.datetime.fromtimestamp(os.path.getctime(abort_path_patch))#os.path.getctime(abort_path_patch))\n",
    "                    #     Abort_dataframe = Abort_dataframe.append({'Job':i,'Timestamp':time_stamp},ignore_index=True)\n",
    "\n",
    "                elif os.path.exists(abort_path):\n",
    "\n",
    "                    abort_file = open(abort_path)\n",
    "                    time_stamp = dt.datetime.fromtimestamp(os.path.getctime(abort_path))#os.path.getctime(abort_path_patch))\n",
    "                    Abort_dataframe = Abort_dataframe.append({'Job':i,'Timestamp':time_stamp,'AbortReason':abort_file.read()},ignore_index=True)\n",
    "                    # if(abort_file.read().__contains__('Respuesta del servicio')):\n",
    "                    #     time_stamp= dt.datetime.fromtimestamp(os.path.getctime(abort_path))\n",
    "                    #     Abort_dataframe = Abort_dataframe.append({'Job':i,'Timestamp':time_stamp},ignore_index=True)\n",
    "        Abort_dataframe['date'] = Abort_dataframe['Timestamp'].dt.date\n",
    "        Abort_dataframe = Abort_dataframe.drop_duplicates()\n",
    "        print('Finaliza funciÃ³n')\n",
    "        return Abort_dataframe\n",
    "    except ValueError:\n",
    "        return ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = ['//10.240.160.176/f$/Network Exporter/Archive/','//10.240.160.161/e$/Network Exporter/Archive/']\n",
    "data = get_aborts_messages(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NE_Invoker_Pending['id'] =\n",
    "NE_Invoker_Pending.apply(lambda x: re.search('20\\d+',x.Version.split('.')[-1]).group(0) + format(sum((ord(x)) for x in x.Version.split('.')[0]),'04d') if 'GIS' in x.Version else format(int(x.Datetime.timestamp()),'015d'),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = NE_Invoker_Pending[NE_Invoker_Pending.KindExecution == 'P']['Version']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "893630ece985437a4d09eac5a1997315286d44e415eee02814b32317a12ecdc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
